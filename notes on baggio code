(1) This is how th code starts. The two-image mapping might be done for every combination of images, it happens for a while

$:./ExploringSfMExec ac_126_box_L/
=========================== Load Images ===========================
....................
 -------------------- extract feature points for all images -------------------
 ------------------------------------- done -----------------------------------
------------ Match img_43.jpg,img_4.jpg ------------
imgpts1 has 2230 points (descriptors 2230)
imgpts2 has 1181 points (descriptors 1181)
F keeping 258 / 709
------------ Match img_44.jpg,img_13.jpg ------------
imgpts1 has 2030 points (descriptors 2030)
imgpts2 has 1087 points (descriptors 1087)
F keeping 351 / 700





(2) Runs depth recovery. This DEFINITELY runs more than once per image, but it doesn't take as long as the matching done above

======================================================================
======================== Depth Recovery Start ========================
======================================================================
F keeping 258 / 709
709 matches before, 258 new matches after Fundamental Matrix
F keeping 331 / 709
709 matches before, 331 new matches after Fundamental Matrix





(3) Starts baseline triangulation. The x, y values in [x,y = X] are not referencing the image names, but they could be referencing the image in some sort of list. Very fast.

=========================== Baseline triangulation ===========================
Find highest match...[0,1 = 60] [0,2 = 43] [0,3 = 71] [0,4 = 54] [0,5 = 56] [0,7 = 85] [0,8 = 37] [0,9 = 46] [0,10 = 43] [0,11 = 55] [0,12 = 45] [0,13 = 48] [0,14 = 43] [0,15 = 52] [0,16 = 46] [0,17 = 59] [0,18 = 88] [0,19 = 57] [1,0 = 65] [1,2 = 59] [1,3 = 45] [1,4 = 59] [1,5 = 59] [1,6 = 30] [1,7 = 49] [1,8 = 63] [1,9 = 41] [1,10 = 54] [1,11 = 62] [1,12 = 71] [1,13 = 60] [1,14 = 54] [1,15 = 65] [1,16 = 56] [1,17 = 64] [1,18 = 50] [1,19 = 63] [2,0 = 45] [2,1 = 56] [2,3 = 52] [2,4 = 54] [2,5 = 53] [2,6 = 30] [2,7 = 58] [2,8 = 49] [2,9 = 50] [2,10 = 49] [2,11 = 42] [2,12 = 64] [2,13 = 51] [2,14 = 42] [2,15 = 70] [2,16 = 53] [2,17 = 43] [2,18 = 62] [2,19 = 68] [3,0 = 71] [3,1 = 45] [3,2 = 51] [3,4 = 55] [3,5 = 68] [3,7 = 71] [3,8 = 35] [3,9 = 49] [3,10 = 50] [3,11 = 52] [3,12 = 44] [3,13 = 46] [3,14 = 51] [3,15 = 52] [3,16 = 49] [3,17 = 56] [3,18 = 69] [3,19 = 47] [4,0 = 52] [4,1 = 54] [4,2 = 57] [4,3 = 54]

(3) Ends like this. Interesting to know that I have 20 images (0-19). Also interesting that both [18, 19 = X] and [19, 18 = X] are run, with slightly different results

[16,1 = 51] [16,2 = 49] [16,3 = 47] [16,4 = 59] [16,5 = 50] [16,6 = 34] [16,7 = 42] [16,8 = 66] [16,9 = 51] [16,10 = 48] [16,11 = 43] [16,12 = 80] [16,13 = 56] [16,14 = 54] [16,15 = 48] [16,17 = 44] [16,18 = 45] [16,19 = 60] [17,0 = 56] [17,1 = 58] [17,2 = 44] [17,3 = 55] [17,4 = 76] [17,5 = 67] [17,7 = 50] [17,8 = 48] [17,9 = 43] [17,10 = 42] [17,11 = 65] [17,12 = 54] [17,13 = 66] [17,14 = 51] [17,15 = 56] [17,16 = 52] [17,18 = 59] [17,19 = 62] [18,0 = 88] [18,1 = 46] [18,2 = 61] [18,3 = 69] [18,4 = 53] [18,5 = 61] [18,7 = 74] [18,8 = 42] [18,9 = 48] [18,10 = 52] [18,11 = 56] [18,12 = 40] [18,13 = 55] [18,14 = 49] [18,15 = 53] [18,16 = 49] [18,17 = 60] [18,19 = 50] [19,0 = 51] [19,1 = 61] [19,2 = 68] [19,3 = 49] [19,4 = 55] [19,5 = 53] [19,6 = 25] [19,7 = 58] [19,8 = 48] [19,9 = 56] [19,10 = 57] [19,11 = 61] [19,12 = 49] [19,13 = 57] [19,14 = 49] [19,15 = 63] [19,16 = 65] [19,17 = 62] [19,18 = 52]






(4) It calculates a bunch of stuff for a single image pair and then starts bundle adjusting... this gets dense. Interestingly, img_1.jpg and img_11.jpg are the first alphabetically, depending on how you sort.

 -------- img_11.jpg and img_1.jpg -------- 
Find camera matrices...F keeping 188 / 252
252 matches before, 188 new matches after Fundamental Matrix
----------------------- SVD ------------------------
U:
[0.2339620203614803, -0.4071080613238958, -0.8829070163009655;
  -0.6055684379680945, 0.6494296864791457, -0.4599216773065614;
  -0.7606238491956824, -0.6422648275631305, 0.09458991124874716]
W:
[55.59370329547554;
  31.52553059087422;
  7.790391998376155e-12]
Vt:
[-0.2245422504161358, 0.8948557491025612, -0.3857641326978843;
  -0.4312347053924064, 0.2637495768432104, 0.8628283662352273;
  0.8738520507747189, 0.3600963051922652, 0.3266699318022663]
----------------------------------------------------
singular values are too far apart
 -------- img_1.jpg and img_11.jpg -------- 
Find camera matrices...F keeping 208 / 252
252 matches before, 208 new matches after Fundamental Matrix
----------------------- SVD ------------------------
U:
[-0.4700197745518268, 0.6983506973610357, 0.5398034040515166;
  -0.8186615173829956, -0.5735354350843935, 0.02916204140190444;
  0.3299617121522146, -0.4282095377241267, 0.8412858374629093]
W:
[120.4099399821992;
  112.9176158435984;
  3.314323832176804e-13]
Vt:
[-0.6686978499800904, 0.5979742284646599, 0.4418936608779305;
  -0.4823827744228769, -0.801165606434628, 0.3541758461644761;
  0.5658180311479056, 0.02367473671088636, 0.8241901858609929]
----------------------------------------------------
Testing P1 
[-0.3882845534519802, 0.05381174520370095, 0.9199670655130695, 0.5398034040515166;
  0.00511410711015722, -0.9981524566784317, 0.06054353091187871, 0.02916204140190444;
  0.9215253395642802, 0.02821292797537583, 0.3872919818896258, 0.8412858374629093]
Triangulating...Done. (208points, 0.00276043s, mean reproj err = 5.35588)
Triangulating...Done. (208points, 0.00273002s, mean reproj err = 5.63939)
208/208 = 100% are in front of camera
0/208 = 0% are in front of camera
Testing P1 
[-0.3882845534519802, 0.05381174520370095, 0.9199670655130695, -0.5398034040515166;
  0.00511410711015722, -0.9981524566784317, 0.06054353091187871, -0.02916204140190444;
  0.9215253395642802, 0.02821292797537583, 0.3872919818896258, -0.8412858374629093]
Triangulating...Done. (208points, 0.00266054s, mean reproj err = 5.35588)
Triangulating...Done. (208points, 0.00322801s, mean reproj err = 5.63939)
0/208 = 0% are in front of camera

(((NOTE: This P1 testing is totally cool and exactly like we've read about!)))

Testing P1
[0.9991455520267133, -0.02825233827058123, -0.03016572968583719, 0.5398034040515166;
  0.02788671059040134, 0.9995332639827157, -0.01247339426563553, 0.02916204140190444;
  0.03050405280748031, 0.01162151342568801, 0.9994670795919268, 0.8412858374629093]
Triangulating...Done. (208points, 0.00268764s, mean reproj err = 22.5526)
Triangulating...Done. (208points, 0.00266107s, mean reproj err = 32.3163)
206/208 = 99.0385% are in front of camera
205/208 = 98.5577% are in front of camera
Done. (0.0182962s)
 Triangulate img_11.jpg and img_1.jpg
Triangulating...Done. (208points, 0.00269065s, mean reproj err = 22.5526)
triangulation reproj error 22.5526
205/208 = 98.5577% are in front of camera
206/208 = 99.0385% are in front of camera
filtered out 71 high-error points
0/137 points were found in other views, adding 137 new
before triangulation: 0 after 137
Taking baseline from img_1.jpg and img_11.jpg
======================== Bundle Adjustment ==========================
N (cams) = 2 M (points) = 137 K (measurements) = 274
intrinsic before bundle = [ 588.608 0 335.927 
0 589.353 253.931 
0 0 1 ]
Read the 3D points.
Read the cameras.

(((NOTE: The following line seems bad)))

Read 0 valid 2D measurements.
mean reprojection error (in pixels): -nan
K0 = [ 1 0 0.570714 
0 1.00127 0.431409 
0 0 1 ]
optimizer status = 2
refined K = [ 1 0 0.570714 
0 1.00127 0.431409 
0 0 1 ]
Knew = [ 588.608 0 335.927 
0 589.353 253.931 
0 0 1 ]
mean reprojection error (in pixels): -nan
use new K 
[588.60773683, 0, 335.9267799;
  0, 589.35313167, 253.93055799;
  0, 0, 1]
Creating point cloud...Done. (2.6947e-05s)
Creating point cloud...Done. (2.2809e-05s)
Show cloud: show cloud A
img_43.jpg: showing 4 cameras
showing 4 lines
found 49 3d-2d point correspondences

(((NOTE: Below there are 17/20 images)))

img_4.jpg: found 107 3d-2d point correspondences
img_14.jpg: found 88 3d-2d point correspondences
img_41.jpg: found 48 3d-2d point correspondences
img_32.jpg: found 62 3d-2d point correspondences
img_34.jpg: found 58 3d-2d point correspondences
img_44.jpg: found 58 3d-2d point correspondences
img_22.jpg: found 82 3d-2d point correspondences
img_21.jpg: found 74 3d-2d point correspondences
img_31.jpg: found 63 3d-2d point correspondences
img_23.jpg: found 78 3d-2d point correspondences
img_3.jpg: found 107 3d-2d point correspondences
img_2.jpg: found 109 3d-2d point correspondences
img_12.jpg: found 88 3d-2d point correspondences
img_24.jpg: found 81 3d-2d point correspondences
img_33.jpg: found 66 3d-2d point correspondences
img_42.jpg: found 64 3d-2d point correspondences
img_13.jpg: found 87 3d-2d point correspondences
-------------------------- img_2.jpg --------------------------
found t = [0.05755886040580704;
  -0.01050384515118541;
  0.1345098750023457]
R = 
[0.9999764102616955, -0.006861941481417634, 0.0003044326508201728;
  0.006858697814977281, 0.9999302593695804, 0.009614294636975506;
  -0.0003703841466792175, -0.00961197982672405, 0.9999537352594842]
 -> img_1.jpg
 Triangulate img_2.jpg and img_1.jpg
Triangulating...Done. (356points, 0.00478811s, mean reproj err = 175.768)
triangulation reproj error 175.768
246/356 = 69.1011% are in front of camera
Triangulation did not succeed
 -> img_11.jpg
 Triangulate img_2.jpg and img_11.jpg
Triangulating...Done. (502points, 0.00661206s, mean reproj err = 22.2377)
triangulation reproj error 22.2377
499/502 = 99.4024% are in front of camera
498/502 = 99.2032% are in front of camera
filtered out 55 high-error points
71/447 points were found in other views, adding 376 new
before triangulation: 137 after 513
======================== Bundle Adjustment ==========================
N (cams) = 5 M (points) = 513 K (measurements) = 1097
intrinsic before bundle = [ 588.608 0 335.927 
0 589.353 253.931 
0 0 1 ]
Read the 3D points.
Read the cameras.
Read 0 valid 2D measurements.
mean reprojection error (in pixels): -nan
K0 = [ 1 0 0.570714 
0 1.00127 0.431409 
0 0 1 ]
optimizer status = 2
refined K = [ 1 0 0.570714 
0 1.00127 0.431409 
0 0 1 ]
Knew = [ 588.608 0 335.927 
0 589.353 253.931 
0 0 1 ]
mean reprojection error (in pixels): -nan
use new K 
[588.60773683, 0, 335.9267799;
  0, 589.35313167, 253.93055799;
  0, 0, 1]
Creating point cloud...Done. (8.4612e-05s)
Creating point cloud...Done. (7.9117e-05s)
Show cloud: show cloud A
img_43.jpg: showing 8 cameras
showing 8 lines
found 215 3d-2d point correspondences
img_4.jpg: found 426 3d-2d point correspondences
img_14.jpg: found 372 3d-2d point correspondences
img_41.jpg: found 215 3d-2d point correspondences
img_32.jpg: found 264 3d-2d point correspondences
img_34.jpg: found 252 3d-2d point correspondences
img_44.jpg: found 212 3d-2d point correspondences
img_22.jpg: found 318 3d-2d point correspondences
img_21.jpg: found 333 3d-2d point correspondences
img_31.jpg: found 272 3d-2d point correspondences
img_23.jpg: found 322 3d-2d point correspondences
img_3.jpg: found 426 3d-2d point correspondences
img_12.jpg: found 390 3d-2d point correspondences
img_24.jpg: found 331 3d-2d point correspondences
img_33.jpg: found 265 3d-2d point correspondences
img_42.jpg: found 243 3d-2d point correspondences
img_13.jpg: found 385 3d-2d point correspondences
-------------------------- img_4.jpg --------------------------
found t = [0.1444289811831047;
  -0.08658212047881064;
  0.3705728558649719]
R = 
[0.9999805618461507, 0.004977103046832104, 0.003755579198742003;
  -0.005044647969885116, 0.9998217240843081, 0.01819537237710599;
  -0.003664349426125055, -0.01821396426763905, 0.9998273971285946]
 -> img_1.jpg
 Triangulate img_4.jpg and img_1.jpg
Triangulating...Done. (278points, 0.0036404s, mean reproj err = 5.15556)
triangulation reproj error 5.15556
183/278 = 65.8273% are in front of camera
Triangulation did not succeed
 -> img_11.jpg
 Triangulate img_4.jpg and img_11.jpg
Triangulating...Done. (590points, 0.00801631s, mean reproj err = 8.72678)
triangulation reproj error 8.72678
589/590 = 99.8305% are in front of camera
588/590 = 99.661% are in front of camera
filtered out 93 high-error points
241/497 points were found in other views, adding 256 new
before triangulation: 513 after 769
 -> img_2.jpg
 Triangulate img_4.jpg and img_2.jpg
Triangulating...Done. (592points, 0.00775918s, mean reproj err = 27.9455)
triangulation reproj error 27.9455
524/592 = 88.5135% are in front of camera
529/592 = 89.3581% are in front of camera
filtered out 98 high-error points
286/494 points were found in other views, adding 208 new
before triangulation: 769 after 977






(5) This bundle adjustment continues like so:
-------------------------- img_23.jpg --------------------------
found t = [0.1090013552658529;
  1.052597832025705;
  -3.787178079533852]
R = 
[0.9926920080865929, -0.1196246743125687, -0.01589070094802868;
  0.1184212502949582, 0.9909988330237239, -0.06243172610296944;
  0.02321604099726461, 0.06009367887914006, 0.9979227250640123]
 -> img_43.jpg
 Triangulate img_23.jpg and img_43.jpg
Triangulating...Done. (859points, 0.0120786s, mean reproj err = 114.363)
triangulation reproj error 114.363
547/859 = 63.6787% are in front of camera
Triangulation did not succeed
 -> img_41.jpg
 Triangulate img_23.jpg and img_41.jpg
Triangulating...Done. (887points, 0.0124185s, mean reproj err = 189.739)
triangulation reproj error 189.739
559/887 = 63.0214% are in front of camera
Triangulation did not succeed
 -> img_32.jpg
 Triangulate img_23.jpg and img_32.jpg
Triangulating...Done. (931points, 0.0124324s, mean reproj err = 154.935)
triangulation reproj error 154.935
603/931 = 64.7691% are in front of camera
Triangulation did not succeed
 -> img_34.jpg
 Triangulate img_23.jpg and img_34.jpg
Triangulating...Done. (973points, 0.012953s, mean reproj err = 124.546)
triangulation reproj error 124.546
640/973 = 65.776% are in front of camera
Triangulation did not succeed
 -> img_44.jpg
 Triangulate img_23.jpg and img_44.jpg
Triangulating...Done. (771points, 0.0107414s, mean reproj err = 52.0594)
triangulation reproj error 52.0594
18/771 = 2.33463% are in front of camera
Triangulation did not succeed
 -> img_22.jpg
 Triangulate img_23.jpg and img_22.jpg
Triangulating...Done. (1141points, 0.0154306s, mean reproj err = 53.7389)
triangulation reproj error 53.7389
636/1141 = 55.7406% are in front of camera
Triangulation did not succeed
 -> img_31.jpg
 Triangulate img_23.jpg and img_31.jpg
Triangulating...Done. (996points, 0.0138964s, mean reproj err = 160.204)
triangulation reproj error 160.204
637/996 = 63.9558% are in front of camera
Triangulation did not succeed
 -> img_24.jpg
 Triangulate img_23.jpg and img_24.jpg
Triangulating...Done. (1144points, 0.0154359s, mean reproj err = 89.9911)
triangulation reproj error 89.9911
707/1144 = 61.8007% are in front of camera
Triangulation did not succeed
 -> img_33.jpg
 Triangulate img_23.jpg and img_33.jpg
Triangulating...Done. (876points, 0.0117163s, mean reproj err = 98.2621)
triangulation reproj error 98.2621
530/876 = 60.5023% are in front of camera
Triangulation did not succeed
 -> img_42.jpg
 Triangulate img_23.jpg and img_42.jpg
Triangulating...Done. (922points, 0.0123225s, mean reproj err = 166.513)
triangulation reproj error 166.513
589/922 = 63.8829% are in front of camera
Triangulation did not succeed
======================== Bundle Adjustment ==========================
N (cams) = 11 M (points) = 3760 K (measurements) = 21040
intrinsic before bundle = [ 528.965 0 347.007 
0 529.635 225.565 
0 0 1 ]
Read the 3D points.
Read the cameras.
Read 21040 valid 2D measurements.
mean reprojection error (in pixels): 1.26731
K0 = [ 1 0 0.656011 
0 1.00127 0.426426 
0 0 1 ]
optimizer status = 1
refined K = [ 1 0 0.656011 
0 1.00127 0.426426 
0 0 1 ]
Knew = [ 528.965 0 347.007 
0 529.635 225.565 
0 0 1 ]
mean reprojection error (in pixels): 1.26731
use new K 
[528.9651555702512, 0, 347.0068218339015;
  0, 529.6350208690413, 225.564746313432;
  0, 0, 1]
Creating point cloud...Done. (0.000717105s)
Creating point cloud...Done. (0.000732119s)
Show cloud: show cloud A

